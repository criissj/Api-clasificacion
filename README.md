# ü§ñ API de Clasificaci√≥n de Texto con RoBERTa

API REST para clasificaci√≥n autom√°tica de texto usando modelos RoBERTa fine-tuned. Sistema completo que incluye entrenamiento del modelo, API de inferencia y documentaci√≥n interactiva.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/Transformers-4.30+-orange.svg)](https://huggingface.co/transformers/)

---

## üìã Tabla de Contenidos

- [Caracter√≠sticas](#-caracter√≠sticas)
- [Arquitectura del Proyecto](#-arquitectura-del-proyecto)
- [Requisitos](#Ô∏è-requisitos)
- [Instalaci√≥n](#-instalaci√≥n)
- [Entrenamiento del Modelo](#-entrenamiento-del-modelo)
- [Uso de la API](#-uso-de-la-api)
- [Endpoints](#-endpoints)
- [Despliegue](#-despliegue)
- [Configuraci√≥n](#Ô∏è-configuraci√≥n)
- [Ejemplos](#-ejemplos)

---

## üöÄ Caracter√≠sticas

### üß† Modelo de IA
- **RoBERTa Fine-tuned:** Modelo transformer especializado en espa√±ol (RoBERTalex)
- **Alta Precisi√≥n:** Entrenamiento con pesos de clase balanceados
- **M√©tricas Detalladas:** F1-score, matriz de confusi√≥n y reportes completos
- **Inferencia R√°pida:** Optimizado para producci√≥n

### ‚ö° API REST
- **Clasificaci√≥n Individual:** Endpoint para textos √∫nicos
- **Procesamiento por Lotes:** Hasta 50 textos simult√°neos
- **Scores de Confianza:** Probabilidades para cada predicci√≥n
- **Health Checks:** Monitoreo del estado del servicio
- **CORS Habilitado:** Listo para integraciones frontend

### üê≥ DevOps
- **Docker Ready:** Contenedorizaci√≥n completa
- **Docker Compose:** Configuraci√≥n para desarrollo y producci√≥n
- **Usuario No-Root:** Seguridad en contenedores
- **Health Checks:** Verificaci√≥n autom√°tica de disponibilidad

### üìä Documentaci√≥n
- **Interfaz Web:** Documentaci√≥n interactiva en `/`
- **Jupyter Notebook:** Proceso completo de entrenamiento documentado
- **README Completo:** Gu√≠as paso a paso

---

## üìÅ Arquitectura del Proyecto

```
Api-clasificacion/
‚îú‚îÄ‚îÄ üìÇ app/                          # Aplicaci√≥n Flask
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Factory de la aplicaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ clasificador/                # M√≥dulo de clasificaci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ endpoints.py             # Endpoints de la API
‚îÇ       ‚îú‚îÄ‚îÄ utils.py                 # Funciones auxiliares
‚îÇ       ‚îî‚îÄ‚îÄ modelo/                  # Modelo entrenado (no en Git)
‚îÇ           ‚îú‚îÄ‚îÄ config.json          # Configuraci√≥n del modelo
‚îÇ           ‚îú‚îÄ‚îÄ labels.json          # Mapeo de categor√≠as
‚îÇ           ‚îú‚îÄ‚îÄ model.safetensors    # Pesos del modelo
‚îÇ           ‚îú‚îÄ‚îÄ tokenizer_config.json
‚îÇ           ‚îú‚îÄ‚îÄ vocab.json
‚îÇ           ‚îî‚îÄ‚îÄ merges.txt
‚îÇ
‚îú‚îÄ‚îÄ üìÇ docker/                       # Configuraci√≥n Docker
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                   # Imagen de producci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ .dockerignore               # Archivos excluidos
‚îÇ
‚îú‚îÄ‚îÄ üìÇ static/                       # Archivos est√°ticos
‚îÇ   ‚îú‚îÄ‚îÄ index.html                   # Documentaci√≥n web
‚îÇ   ‚îî‚îÄ‚îÄ utem.png                     # Logo
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                         # Datos de entrenamiento (crear)
‚îÇ   ‚îî‚îÄ‚îÄ consultas_modelo_ia.xlsx    # Dataset
‚îÇ
‚îú‚îÄ‚îÄ üìÑ app.py                        # Punto de entrada
‚îú‚îÄ‚îÄ üìÑ requirements.txt              # Dependencias Python
‚îú‚îÄ‚îÄ üìÑ docker-compose.yml            # Orquestaci√≥n producci√≥n
‚îú‚îÄ‚îÄ üìÑ docker-compose.dev.yml        # Orquestaci√≥n desarrollo
‚îú‚îÄ‚îÄ üìÑ MODELO_DE_CLASIFICACION.ipynb # Notebook de entrenamiento
‚îú‚îÄ‚îÄ üìÑ .gitignore                    # Archivos ignorados
‚îú‚îÄ‚îÄ üìÑ .env.example                  # Plantilla de variables
‚îî‚îÄ‚îÄ üìÑ README.md                     # Este archivo
```

---

## ‚öôÔ∏è Requisitos

### Software Necesario
- **Python:** 3.10 o superior
- **pip:** Gestor de paquetes de Python
- **Docker:** (Opcional) Para contenedorizaci√≥n
- **Docker Compose:** (Opcional) Para orquestaci√≥n

### Dependencias Principales
```
flask>=2.3.0              # Framework web
flask-cors>=4.0.0         # CORS para API
torch>=2.0.0              # PyTorch para ML
transformers>=4.30.0      # Modelos Hugging Face
tokenizers>=0.13.0        # Tokenizaci√≥n r√°pida
numpy>=1.24.0             # Operaciones num√©ricas
scipy>=1.10.0             # Funciones cient√≠ficas
```

### Hardware Recomendado
- **RAM:** M√≠nimo 4GB (8GB recomendado)
- **CPU:** 2+ cores
- **GPU:** (Opcional) Para entrenamiento m√°s r√°pido
- **Disco:** 2GB libres para modelo y dependencias

---

## üîß Instalaci√≥n

### 1Ô∏è‚É£ Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/Api-clasificacion.git
cd Api-clasificacion
```

### 2Ô∏è‚É£ Crear Entorno Virtual

**Linux/macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### 3Ô∏è‚É£ Instalar Dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4Ô∏è‚É£ Configurar Variables de Entorno

```bash
# Copiar plantilla
cp .env.example .env

# Editar .env con tus valores
nano .env  # o usa tu editor preferido
```

**Contenido de `.env`:**
```bash
# Flask Configuration
FLASK_SECRET_KEY=tu-clave-secreta-super-segura
FLASK_ENV=development
FLASK_DEBUG=True

# Classifier Configuration
MODEL_PATH=./app/clasificador/modelo
MAX_TEXT_LENGTH=512
```

### 5Ô∏è‚É£ Preparar Estructura de Carpetas

```bash
# Crear carpeta para datos
mkdir -p data

# Crear carpeta para el modelo (si no existe)
mkdir -p app/clasificador/modelo
```

---

## üéì Entrenamiento del Modelo

### Preparaci√≥n de Datos

1. **Coloca tu dataset** en `data/consultas_modelo_ia.xlsx`
2. El archivo debe tener las columnas:
   - `cns_descripcion`: Texto a clasificar
   - `clasificaciones`: Categor√≠a/etiqueta

### Ejecutar Notebook de Entrenamiento

```bash
# Instalar Jupyter (si no lo tienes)
pip install jupyter notebook

# Abrir notebook
jupyter notebook MODELO_DE_CLASIFICACION.ipynb
```

### Proceso de Entrenamiento

El notebook incluye:

1. **üì• Carga de Datos:** Lectura local del Excel
2. **üßπ Preprocesamiento:** Limpieza y normalizaci√≥n de texto
3. **‚úÇÔ∏è Divisi√≥n:** Train (80%), Validaci√≥n (10%), Test (10%)
4. **üî§ Tokenizaci√≥n:** Con RoBERTalex tokenizer
5. **‚öñÔ∏è Balanceo:** C√°lculo de pesos de clase
6. **üèãÔ∏è Entrenamiento:** 12 √©pocas con early stopping
7. **üìä Evaluaci√≥n:** M√©tricas y matriz de confusi√≥n
8. **üíæ Guardado:** Modelo en `app/clasificador/modelo/`

### Resultados Esperados

Despu√©s del entrenamiento tendr√°s:
- ‚úÖ Modelo entrenado en `app/clasificador/modelo/`
- ‚úÖ Archivo `labels.json` con categor√≠as
- ‚úÖ Reporte de m√©tricas (F1-score, precisi√≥n, recall)
- ‚úÖ Matriz de confusi√≥n visualizada
- ‚úÖ Archivo `predicciones.xlsx` con resultados de test

---

## üöÄ Uso de la API

### Iniciar Servidor Local

```bash
# Activar entorno virtual
source venv/bin/activate  # Linux/macOS
# venv\Scripts\activate   # Windows

# Ejecutar API
python app.py
```

La API estar√° disponible en: **http://localhost:5000**

### Verificar Estado

```bash
curl http://localhost:5000/health
```

**Respuesta:**
```json
{
  "status": "ok",
  "service": "classifier-api"
}
```

### Documentaci√≥n Interactiva

Abre en tu navegador: **http://localhost:5000**

---

## üì° Endpoints

### 1. Clasificar Texto Individual

**Endpoint:** `POST /api/classifier/predict`

**Request:**
```json
{
  "text": "Buenos d√≠as, necesito informaci√≥n sobre inscripci√≥n de ramos"
}
```

**Response:**
```json
{
  "text": "Buenos d√≠as, necesito informaci√≥n sobre inscripci√≥n de ramos",
  "predicted_class": 1,
  "categoria": "Jefe Carrera",
  "confidence": 0.9234,
  "timestamp": "2024-01-15T10:30:00.123456"
}
```

**C√≥digos de Estado:**
- `200`: Clasificaci√≥n exitosa
- `400`: Datos inv√°lidos
- `503`: Modelo no disponible

---

### 2. Clasificaci√≥n por Lotes

**Endpoint:** `POST /api/classifier/batch-predict`

**Request:**
```json
{
  "texts": [
    "Consulta sobre horarios",
    "Problema con mi matr√≠cula",
    "Solicitud de certificado"
  ]
}
```

**Response:**
```json
{
  "results": [
    {
      "index": 0,
      "text": "Consulta sobre horarios",
      "predicted_class": 1,
      "categoria": "Jefe Carrera",
      "confidence": 0.8756
    },
    {
      "index": 1,
      "text": "Problema con mi matr√≠cula",
      "predicted_class": 3,
      "categoria": "SISEI",
      "confidence": 0.9123
    },
    {
      "index": 2,
      "text": "Solicitud de certificado",
      "predicted_class": 2,
      "categoria": "Otro",
      "confidence": 0.7845
    }
  ],
  "total_processed": 3,
  "timestamp": "2024-01-15T10:30:00.123456"
}
```

**L√≠mites:**
- M√°ximo 50 textos por solicitud
- M√°ximo 512 caracteres por texto

---

### 3. Estado del Clasificador

**Endpoint:** `GET /api/classifier/health`

**Response:**
```json
{
  "status": "ok",
  "model_loaded": true,
  "model_path": "./app/clasificador/modelo",
  "categories_count": 4
}
```

---

### 4. Obtener Categor√≠as

**Endpoint:** `GET /api/classifier/categories`

**Response:**
```json
{
  "categories": {
    "0": "Docencia",
    "1": "Jefe Carrera",
    "2": "Otro",
    "3": "SISEI"
  },
  "count": 4
}
```

---

### 5. Informaci√≥n de la API

**Endpoint:** `GET /api`

**Response:**
```json
{
  "name": "API de Clasificaci√≥n de Texto",
  "version": "1.0.0",
  "description": "API para clasificaci√≥n de texto usando RoBERTa",
  "endpoints": {
    "predict": "/api/classifier/predict",
    "batch_predict": "/api/classifier/batch-predict",
    "health": "/api/classifier/health",
    "categories": "/api/classifier/categories"
  }
}
```

---

## üê≥ Despliegue

### Opci√≥n 1: Docker Compose (Recomendado)

**Producci√≥n:**
```bash
docker-compose up -d --build
```

**Desarrollo:**
```bash
docker-compose -f docker-compose.dev.yml up --build
```

**Ver logs:**
```bash
docker-compose logs -f classifier-api
```

**Detener:**
```bash
docker-compose down
```

---

### Opci√≥n 2: Docker Manual

**Construir imagen:**
```bash
docker build -t classifier-api:latest -f docker/Dockerfile .
```

**Ejecutar contenedor:**
```bash
docker run -d \
  --name classifier-api \
  -p 5000:5000 \
  -e FLASK_SECRET_KEY=tu-clave-secreta \
  -e MODEL_PATH=/app/app/clasificador/modelo \
  classifier-api:latest
```

---

### Opci√≥n 3: Servidor de Producci√≥n (Gunicorn)

**Instalar Gunicorn:**
```bash
pip install gunicorn
```

**Ejecutar:**
```bash
gunicorn --bind 0.0.0.0:5000 \
         --workers 4 \
         --timeout 120 \
         --access-logfile - \
         --error-logfile - \
         app:app
```

---

## üõ†Ô∏è Configuraci√≥n

### Variables de Entorno

| Variable | Descripci√≥n | Valor por Defecto |
|----------|-------------|-------------------|
| `FLASK_SECRET_KEY` | Clave secreta de Flask | `classifier-api-key` |
| `FLASK_ENV` | Entorno de Flask | `development` |
| `FLASK_DEBUG` | Modo debug | `True` |
| `MODEL_PATH` | Ruta del modelo | `./app/clasificador/modelo` |
| `MAX_TEXT_LENGTH` | Longitud m√°xima de texto | `512` |

### Estructura del Modelo

El directorio `app/clasificador/modelo/` debe contener:

```
modelo/
‚îú‚îÄ‚îÄ config.json              # Configuraci√≥n del modelo RoBERTa
‚îú‚îÄ‚îÄ labels.json              # Mapeo de clases a etiquetas
‚îú‚îÄ‚îÄ model.safetensors        # Pesos del modelo (formato seguro)
‚îú‚îÄ‚îÄ tokenizer_config.json    # Configuraci√≥n del tokenizer
‚îú‚îÄ‚îÄ vocab.json               # Vocabulario del tokenizer
‚îú‚îÄ‚îÄ merges.txt               # Merges BPE del tokenizer
‚îî‚îÄ‚îÄ special_tokens_map.json  # Tokens especiales
```

**Formato de `labels.json`:**
```json
{
  "0": "Docencia",
  "1": "Jefe Carrera",
  "2": "Otro",
  "3": "SISEI"
}
```

---

## üí° Ejemplos

### Python

```python
import requests

# URL de la API
API_URL = "http://localhost:5000/api/classifier"

# Clasificar un texto
def clasificar_texto(texto):
    response = requests.post(
        f"{API_URL}/predict",
        json={"text": texto}
    )
    return response.json()

# Ejemplo de uso
resultado = clasificar_texto("Necesito ayuda con mi inscripci√≥n de ramos")
print(f"Categor√≠a: {resultado['categoria']}")
print(f"Confianza: {resultado['confidence']:.2%}")

# Clasificaci√≥n por lotes
def clasificar_lote(textos):
    response = requests.post(
        f"{API_URL}/batch-predict",
        json={"texts": textos}
    )
    return response.json()

# Ejemplo de lote
textos = [
    "Consulta sobre horarios",
    "Problema con certificado",
    "Solicitud de reuni√≥n"
]
resultados = clasificar_lote(textos)
for r in resultados['results']:
    print(f"{r['text']} -> {r['categoria']} ({r['confidence']:.2%})")
```

---

### JavaScript/Node.js

```javascript
// Clasificar texto individual
async function clasificarTexto(texto) {
    const response = await fetch('http://localhost:5000/api/classifier/predict', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ text: texto })
    });
    return await response.json();
}

// Uso
clasificarTexto('Necesito informaci√≥n sobre mi matr√≠cula')
    .then(resultado => {
        console.log(`Categor√≠a: ${resultado.categoria}`);
        console.log(`Confianza: ${(resultado.confidence * 100).toFixed(2)}%`);
    });

// Clasificaci√≥n por lotes
async function clasificarLote(textos) {
    const response = await fetch('http://localhost:5000/api/classifier/batch-predict', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({ texts: textos })
    });
    return await response.json();
}
```

---

### cURL

```bash
# Clasificar texto
curl -X POST http://localhost:5000/api/classifier/predict \
  -H "Content-Type: application/json" \
  -d '{"text": "Consulta sobre inscripci√≥n de asignaturas"}'

# Clasificaci√≥n por lotes
curl -X POST http://localhost:5000/api/classifier/batch-predict \
  -H "Content-Type: application/json" \
  -d '{
    "texts": [
      "Problema con mi horario",
      "Solicitud de certificado",
      "Consulta acad√©mica"
    ]
  }'

# Verificar estado
curl http://localhost:5000/api/classifier/health

# Obtener categor√≠as
curl http://localhost:5000/api/classifier/categories
```

---

## üß™ Testing

### Tests Manuales

```bash
# Test de clasificaci√≥n
python -c "
import requests
r = requests.post(
    'http://localhost:5000/api/classifier/predict',
    json={'text': 'Necesito ayuda con mi inscripci√≥n'}
)
print(r.json())
"

# Test de health check
python -c "
import requests
r = requests.get('http://localhost:5000/api/classifier/health')
print(r.json())
"
```

### Tests Automatizados (Opcional)

```bash
# Instalar pytest
pip install pytest requests

# Crear archivo test_api.py
# Ejecutar tests
pytest tests/ -v
```

---

## üìä L√≠mites y Restricciones

| L√≠mite | Valor |
|--------|-------|
| Longitud m√°xima por texto | 512 caracteres |
| Textos por batch | 50 m√°ximo |
| Timeout por request | 30 segundos |
| Tama√±o del modelo | ~500 MB |
| RAM requerida | 4 GB m√≠nimo |

---

## üîí Seguridad

### Implementado ‚úÖ
- Validaci√≥n de entrada (longitud, formato)
- Manejo seguro de errores
- CORS configurado
- Usuario no-root en Docker
- Variables de entorno para secretos
- Health checks autom√°ticos

### Pendiente üîÑ
- Rate limiting
- Autenticaci√≥n JWT
- Logging avanzado
- Monitoreo con Prometheus
- SSL/TLS en producci√≥n

---

## üêõ Troubleshooting

### Problema: Modelo no se carga

**S√≠ntoma:** Error 503 al hacer requests

**Soluci√≥n:**
```bash
# Verificar que existe el modelo
ls -la app/clasificador/modelo/

# Verificar permisos
chmod -R 755 app/clasificador/modelo/

# Verificar logs
docker-compose logs classifier-api
```

---

### Problema: Error de memoria

**S√≠ntoma:** `RuntimeError: CUDA out of memory`

**Soluci√≥n:**
```python
# En endpoints.py, reducir batch size o usar CPU
device = torch.device("cpu")  # Forzar CPU
```

---

### Problema: Puerto 5000 ocupado

**S√≠ntoma:** `Address already in use`

**Soluci√≥n:**
```bash
# Cambiar puerto en app.py
app.run(port=5001)

# O matar proceso
lsof -ti:5000 | xargs kill -9  # Linux/macOS
netstat -ano | findstr :5000   # Windows
```

---

## üìö Recursos Adicionales

- **Documentaci√≥n Flask:** https://flask.palletsprojects.com/
- **Transformers Hugging Face:** https://huggingface.co/docs/transformers/
- **RoBERTalex:** https://huggingface.co/PlanTL-GOB-ES/RoBERTalex
- **Docker Docs:** https://docs.docker.com/

---

## ü§ù Contribuci√≥n

1. Fork del repositorio
2. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
3. Commit cambios: `git commit -am 'Agregar nueva funcionalidad'`
4. Push a la rama: `git push origin feature/nueva-funcionalidad`
5. Crear Pull Request

---

## üìÑ Licencia

Este proyecto est√° bajo la **Licencia MIT**.

---

## üë• Autores

- **Tu Nombre** - *Desarrollo inicial* - [GitHub](https://github.com/tu-usuario)

---

## üôè Agradecimientos

- Modelo base: [RoBERTalex](https://huggingface.co/PlanTL-GOB-ES/RoBERTalex) por PlanTL-GOB-ES
- Framework: [Hugging Face Transformers](https://huggingface.co/transformers/)
- Universidad Tecnol√≥gica Metropolitana (UTEM)

---

## üìû Soporte

- üêõ **Issues:** [GitHub Issues](https://github.com/tu-usuario/Api-clasificacion/issues)
- üìß **Email:** tu-email@ejemplo.com
- üìñ **Docs:** http://localhost:5000 (cuando la API est√° ejecut√°ndose)

---

<div align="center">

**üöÄ ¬°API lista para clasificar texto con IA! ü§ñ**

Hecho con ‚ù§Ô∏è para la comunidad UTEM

</div>
