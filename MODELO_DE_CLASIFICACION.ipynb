{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ Entrenamiento de Modelo RoBERTa para Clasificaci√≥n de Texto\n",
        "\n",
        "Este notebook entrena un modelo RoBERTa fine-tuned para clasificar consultas de texto.\n",
        "\n",
        "## üìã Contenido\n",
        "1. Instalaci√≥n de dependencias\n",
        "2. Carga y preprocesamiento de datos\n",
        "3. Tokenizaci√≥n\n",
        "4. Configuraci√≥n y entrenamiento del modelo\n",
        "5. Evaluaci√≥n y m√©tricas\n",
        "6. Guardado del modelo\n",
        "7. Inferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Instalaci√≥n de Dependencias\n",
        "\n",
        "Instalamos las librer√≠as necesarias con versiones compatibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Desinstalar versiones conflictivas\n",
        "!pip uninstall -y pyarrow apache-beam\n",
        "\n",
        "# Instalar versiones espec√≠ficas compatibles\n",
        "!pip install -U \"pyarrow==16.1.0\" \"pandas==2.2.2\" \"datasets==2.19.1\"\n",
        "!pip install -U \"transformers>=4.41.0\" \"sentence-transformers>=2.5.1\" datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Importaci√≥n de Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Librer√≠as est√°ndar\n",
        "import os\n",
        "import json\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "# An√°lisis de datos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualizaci√≥n\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Transformers\n",
        "from transformers import (\n",
        "    RobertaTokenizer,\n",
        "    RobertaForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "\n",
        "# Desactivar Weights & Biases\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "print(\"‚úÖ Librer√≠as importadas correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Configuraci√≥n de Rutas\n",
        "\n",
        "**IMPORTANTE:** Modifica estas rutas seg√∫n tu sistema local."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÅ CONFIGURACI√ìN DE RUTAS - MODIFICAR SEG√öN TU SISTEMA\n",
        "DATA_PATH = './data/consultas_modelo_ia.xlsx'  # Ruta al archivo Excel con los datos\n",
        "MODEL_SAVE_PATH = './modelo_entrenado'  # Carpeta donde se guardar√° el modelo\n",
        "PREDICTIONS_PATH = './predicciones.xlsx'  # Archivo de salida con predicciones\n",
        "\n",
        "# Crear carpeta para el modelo si no existe\n",
        "os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Ruta de datos: {DATA_PATH}\")\n",
        "print(f\"üíæ Modelo se guardar√° en: {MODEL_SAVE_PATH}\")\n",
        "print(f\"üìä Predicciones se guardar√°n en: {PREDICTIONS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Carga y Preprocesamiento de Datos\n",
        "\n",
        "Cargamos el archivo Excel local y limpiamos el texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n de limpieza de texto\n",
        "def limpiar_texto(texto):\n",
        "    \"\"\"Limpia y normaliza el texto de entrada.\"\"\"\n",
        "    texto = str(texto).lower()\n",
        "    # Normalizar caracteres Unicode\n",
        "    texto = unicodedata.normalize('NFD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
        "    # Eliminar caracteres especiales excepto puntuaci√≥n b√°sica\n",
        "    texto = re.sub(r\"[^a-z0-9¬ø?¬°!., ]\", \" \", texto)\n",
        "    # Eliminar espacios m√∫ltiples\n",
        "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
        "    return texto\n",
        "\n",
        "# Cargar datos desde archivo Excel local\n",
        "print(\"üì• Cargando datos...\")\n",
        "df = pd.read_excel(DATA_PATH)\n",
        "\n",
        "print(f\"‚úÖ Datos cargados: {len(df)} registros\")\n",
        "print(f\"üìã Columnas disponibles: {df.columns.tolist()}\")\n",
        "\n",
        "# Aplicar limpieza\n",
        "df['cns_descripcion'] = df['cns_descripcion'].fillna('').apply(limpiar_texto)\n",
        "df['clasificaciones'] = df['clasificaciones'].astype(str)\n",
        "\n",
        "# Codificar etiquetas como n√∫meros\n",
        "df['clasificacion_encoded'] = df['clasificaciones'].astype('category').cat.codes\n",
        "\n",
        "# Obtener categor√≠as\n",
        "categorias = df['clasificaciones'].astype('category').cat.categories.to_list()\n",
        "print(f\"\\nüè∑Ô∏è  Categor√≠as encontradas: {categorias}\")\n",
        "print(f\"üìä Distribuci√≥n de clases:\\n{df['clasificaciones'].value_counts()}\")\n",
        "\n",
        "# Mostrar ejemplos\n",
        "print(\"\\nüìù Ejemplos de datos:\")\n",
        "print(df[['cns_descripcion', 'clasificaciones']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Divisi√≥n del Dataset\n",
        "\n",
        "Dividimos los datos en conjuntos de entrenamiento (80%), validaci√≥n (10%) y prueba (10%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extraer textos y etiquetas\n",
        "data_texts = df['cns_descripcion'].to_list()\n",
        "data_labels = df['clasificacion_encoded'].to_list()\n",
        "\n",
        "# Divisi√≥n estratificada\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    data_texts, data_labels, \n",
        "    test_size=0.2, \n",
        "    stratify=data_labels, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, temp_labels, \n",
        "    test_size=0.5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"üìä Distribuci√≥n de datos:\")\n",
        "print(f\"  üîπ Entrenamiento: {len(train_texts)} textos ({len(train_texts)/len(data_texts)*100:.1f}%)\")\n",
        "print(f\"  üîπ Validaci√≥n:    {len(val_texts)} textos ({len(val_texts)/len(data_texts)*100:.1f}%)\")\n",
        "print(f\"  üîπ Prueba:        {len(test_texts)} textos ({len(test_texts)/len(data_texts)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Tokenizaci√≥n\n",
        "\n",
        "Utilizamos el tokenizador de RoBERTalex (modelo en espa√±ol)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar tokenizador\n",
        "print(\"üî§ Cargando tokenizador RoBERTalex...\")\n",
        "tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/RoBERTalex')\n",
        "\n",
        "# Tokenizar conjuntos de datos\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "print(f\"‚öôÔ∏è  Tokenizando con longitud m√°xima: {MAX_LENGTH}\")\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=MAX_LENGTH)\n",
        "\n",
        "# Crear clase Dataset personalizada\n",
        "class EmailDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset personalizado para clasificaci√≥n de texto.\"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Crear datasets\n",
        "train_dataset = EmailDataset(train_encodings, train_labels)\n",
        "val_dataset = EmailDataset(val_encodings, val_labels)\n",
        "test_dataset = EmailDataset(test_encodings, test_labels)\n",
        "\n",
        "print(\"‚úÖ Tokenizaci√≥n completada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Configuraci√≥n del Modelo\n",
        "\n",
        "Calculamos pesos de clase para balancear el entrenamiento y configuramos el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcular pesos de clase para balancear\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_labels),\n",
        "    y=train_labels\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "print(f\"üñ•Ô∏è  Dispositivo: {device}\")\n",
        "print(f\"‚öñÔ∏è  Pesos de clase: {class_weights}\")\n",
        "\n",
        "# Cargar modelo preentrenado\n",
        "print(\"\\nü§ñ Cargando modelo RoBERTalex...\")\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    'PlanTL-GOB-ES/RoBERTalex',\n",
        "    num_labels=len(categorias)\n",
        ").to(device)\n",
        "\n",
        "print(\"‚úÖ Modelo cargado correctamente\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ Trainer Personalizado con Pesos de Clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n de m√©tricas\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"Calcula F1-score ponderado.\"\"\"\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    return {\"f1\": f1}\n",
        "\n",
        "# Trainer con pesos de clase\n",
        "class WeightedTrainer(Trainer):\n",
        "    \"\"\"Trainer personalizado que aplica pesos de clase en la funci√≥n de p√©rdida.\"\"\"\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print(\"‚úÖ Trainer personalizado configurado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Configuraci√≥n de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Argumentos de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=12,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=100,\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "# Instanciar trainer\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Configuraci√≥n de entrenamiento lista\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîü Entrenamiento del Modelo\n",
        "\n",
        "**NOTA:** Este proceso puede tardar varios minutos dependiendo del hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üöÄ Iniciando entrenamiento...\\n\")\n",
        "trainer.train()\n",
        "print(\"\\n‚úÖ Entrenamiento completado\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£1Ô∏è‚É£ Evaluaci√≥n en Conjunto de Prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Realizar predicciones\n",
        "print(\"üîç Evaluando modelo en conjunto de prueba...\")\n",
        "predictions = trainer.predict(test_dataset)\n",
        "y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()\n",
        "y_true = test_labels\n",
        "\n",
        "# Reporte de clasificaci√≥n\n",
        "print(\"\\nüìä Reporte de Clasificaci√≥n:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=categorias))\n",
        "\n",
        "# Matriz de confusi√≥n\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=categorias, yticklabels=categorias)\n",
        "plt.xlabel('Clase Predicha')\n",
        "plt.ylabel('Clase Real')\n",
        "plt.title('Matriz de Confusi√≥n')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úÖ Evaluaci√≥n completada\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£2Ô∏è‚É£ Guardar Modelo y Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Guardar modelo y tokenizador\n",
        "print(f\"üíæ Guardando modelo en: {MODEL_SAVE_PATH}\")\n",
        "model.save_pretrained(MODEL_SAVE_PATH)\n",
        "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
        "\n",
        "# Guardar etiquetas\n",
        "with open(f\"{MODEL_SAVE_PATH}/labels.json\", \"w\", encoding='utf-8') as f:\n",
        "    json.dump(categorias, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"‚úÖ Modelo guardado correctamente\")\n",
        "\n",
        "# Exportar predicciones\n",
        "df_pred = pd.DataFrame({\n",
        "    \"Texto\": test_texts,\n",
        "    \"Clase Real\": [categorias[i] for i in y_true],\n",
        "    \"Clase Predicha\": [categorias[i] for i in y_pred]\n",
        "})\n",
        "\n",
        "df_pred.to_excel(PREDICTIONS_PATH, index=False)\n",
        "print(f\"üìä Predicciones exportadas a: {PREDICTIONS_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£3Ô∏è‚É£ Inferencia - Ejemplo de Uso\n",
        "\n",
        "Prueba el modelo entrenado con un texto de ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predecir_texto(texto, modelo, tokenizador, categorias, max_length=256):\n",
        "    \"\"\"Predice la categor√≠a de un texto.\"\"\"\n",
        "    # Limpiar texto\n",
        "    texto_limpio = limpiar_texto(texto)\n",
        "    \n",
        "    # Tokenizar\n",
        "    inputs = tokenizador(\n",
        "        texto_limpio, \n",
        "        return_tensors=\"pt\", \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=max_length\n",
        "    ).to(device)\n",
        "    \n",
        "    # Predecir\n",
        "    modelo.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = modelo(**inputs)\n",
        "    \n",
        "    # Obtener clase predicha y confianza\n",
        "    logits = outputs.logits\n",
        "    probs = torch.softmax(logits, dim=1)\n",
        "    predicted_class = torch.argmax(probs, axis=1).item()\n",
        "    confidence = probs[0][predicted_class].item()\n",
        "    \n",
        "    return categorias[predicted_class], confidence\n",
        "\n",
        "# Ejemplo de uso\n",
        "texto_ejemplo = \"Buenos d√≠as, quisiera solicitar una reuni√≥n para revisar mis asignaturas pendientes\"\n",
        "\n",
        "categoria, confianza = predecir_texto(texto_ejemplo, model, tokenizer, categorias)\n",
        "\n",
        "print(\"\\nüîÆ Predicci√≥n:\")\n",
        "print(f\"  üìù Texto: {texto_ejemplo}\")\n",
        "print(f\"  üè∑Ô∏è  Categor√≠a: {categoria}\")\n",
        "print(f\"  üìä Confianza: {confianza:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£4Ô∏è‚É£ Clasificaci√≥n por Lotes (Opcional)\n",
        "\n",
        "Clasifica m√∫ltiples textos de un archivo Excel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPCIONAL: Clasificar archivo Excel completo\n",
        "# Descomenta y modifica la ruta si necesitas clasificar un archivo nuevo\n",
        "\n",
        "# input_excel = './data/consultas_nuevas.xlsx'\n",
        "# output_excel = './consultas_clasificadas.xlsx'\n",
        "\n",
        "# df_nuevas = pd.read_excel(input_excel)\n",
        "\n",
        "# def predecir_batch(texto):\n",
        "#     categoria, _ = predecir_texto(texto, model, tokenizer, categorias)\n",
        "#     return categoria\n",
        "\n",
        "# df_nuevas['clasificacion_predicha'] = df_nuevas['cns_descripcion'].apply(predecir_batch)\n",
        "# df_nuevas.to_excel(output_excel, index=False)\n",
        "\n",
        "# print(f\"‚úÖ Clasificaci√≥n por lotes completada: {output_excel}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéâ ¬°Entrenamiento Completado!\n",
        "\n",
        "### üì¶ Archivos Generados:\n",
        "- **Modelo entrenado:** `{MODEL_SAVE_PATH}/`\n",
        "- **Predicciones:** `{PREDICTIONS_PATH}`\n",
        "\n",
        "### üöÄ Pr√≥ximos Pasos:\n",
        "1. Integrar el modelo en la API Flask\n",
        "2. Realizar pruebas con datos reales\n",
        "3. Ajustar hiperpar√°metros si es necesario\n",
        "4. Desplegar en producci√≥n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
